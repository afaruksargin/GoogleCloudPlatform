{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83kr3HtNDUWd",
        "outputId": "f58a734d-6ffa-440f-97dd-419c535328fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod<2.0,>=1.7 (from apache-beam)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4.0 (from apache-beam)\n",
            "  Downloading orjson-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam)\n",
            "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam)\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.57.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam)\n",
            "  Downloading hdfs-2.7.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (0.22.0)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.23.5)\n",
            "Collecting objsize<0.7.0,>=0.6.1 (from apache-beam)\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam)\n",
            "  Downloading pymongo-4.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (603 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.6/603.6 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.22.3)\n",
            "Requirement already satisfied: protobuf<4.24.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2023.3)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2023.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (4.7.1)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (9.0.0)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam) (3.1.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2023.7.22)\n",
            "Building wheels for collected packages: crcmod, dill, hdfs, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31403 sha256=25076a6e541c950f2c7a45f87d87f8603ff04d9f45ee564f67ad537e31dbe2db\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78541 sha256=b67a017ba8538a93ceb2f12319da27d74557e3eafbff134ec7c424f05dba53e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.2-py3-none-any.whl size=34168 sha256=541abf4de4cce43dbc9ebebe0de986c68156e2461e6c6f692d920c77e2101de0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/39/8e/e1905de9af8ae74911cd3e53e721995cd230816f63776e5825\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=9bbf66ce6782fd346e1be7671bbc1881be9d0d0f00dceedce73eabfe671b2dc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill hdfs docopt\n",
            "Installing collected packages: docopt, crcmod, zstandard, orjson, objsize, fasteners, fastavro, dnspython, dill, pymongo, hdfs, apache-beam\n",
            "Successfully installed apache-beam-2.49.0 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.8.2 fasteners-0.18 hdfs-2.7.2 objsize-0.6.1 orjson-3.9.4 pymongo-4.4.1 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "pip install apache-beam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam"
      ],
      "metadata": {
        "id": "8gU1AcU0I16s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CoGroupByKey\n",
        "CoGroupByKey, Apache Beam içinde iki veya daha fazla PCollection'ı anahtarlarına göre gruplamak ve bu grupları işlemek için kullanılan bir işlemdir. Bu işlem, bir anahtara sahip her PCollection öğesini bir araya getirir ve bu öğeleri anahtarlarına göre gruplar.\n",
        "\n",
        "Bir CoGroupByKey işlemi, birden fazla PCollection'ın her birinin aynı anahtara sahip öğelerini birleştirir ve sonuç olarak her anahtar için bir grup oluşturur. Her grup, farklı PCollection'lardan gelen öğeleri içerebilir. Bu işlem, özellikle birden fazla veri kaynağını birleştirip analiz etmeniz gereken senaryolarda kullanışlıdır."
      ],
      "metadata": {
        "id": "H5hrgrA2IotA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Bu sadece 2 argüman alan yerlerde işe yaramaktadır.\"\"\"\n",
        "with beam.Pipeline() as pipeline:\n",
        "    orders = pipeline | 'Create orders' >> beam.Create([\n",
        "        ('order-1', 'product-1'),\n",
        "        ('order-1', 'product-2'),\n",
        "        ('order-2', 'product-1'),\n",
        "        ('order-2', 'product-3'),\n",
        "    ])\n",
        "\n",
        "    products = pipeline | 'Create products' >> beam.Create([\n",
        "        ('product-1', 'Apple'),\n",
        "        ('product-2', 'Banana'),\n",
        "        ('product-3', 'Orange'),\n",
        "    ])\n",
        "\n",
        "    grouped_data = (({\n",
        "        'orders': orders, 'products': products\n",
        "    } )\n",
        "    | 'Merge' >> beam.CoGroupByKey()\n",
        "    | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "B5l5qHVjD4K5",
        "outputId": "c47cee65-ca5d-481d-fee7-77976fced64c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('order-1', {'orders': ['product-1', 'product-2'], 'products': []})\n",
            "('order-2', {'orders': ['product-1', 'product-3'], 'products': []})\n",
            "('product-1', {'orders': [], 'products': ['Apple']})\n",
            "('product-2', {'orders': [], 'products': ['Banana']})\n",
            "('product-3', {'orders': [], 'products': ['Orange']})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CombineGlobally\n",
        "\n",
        "CombineGlobally, Apache Beam içinde bir PCollection'ın tüm öğelerini birleştirip bir tek sonuç üretmek için kullanılan bir dönüşüm işlemidir. Bu işlem, veri akışındaki tüm öğeleri toplayarak, ortalama hesaplayarak, en büyük veya en küçük değeri bulup, özel bir işlem yaparak veya özel bir işlevi kullanarak sonuç üretmek için kullanılabilir.\n",
        "\n",
        "CombineGlobally işlemi, birleştirme işlemi sırasında tüm öğelerin global bir şekilde işlenmesini sağlar. Yani, her öğe ayrı ayrı işlenmez, tamamı işlenir ve sonuç üretilir."
      ],
      "metadata": {
        "id": "nkyKAvv4Bttf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    numbers = pipeline | 'Create numbers' >> beam.Create([1, 2, 3, 4, 5])\n",
        "\n",
        "    total_sum = numbers | 'Calculate total sum' >> beam.CombineGlobally(sum)\n",
        "    average = numbers | 'Calculate average' >> beam.CombineGlobally(beam.combiners.MeanCombineFn())\n",
        "\n",
        "    total_sum | 'Print total sum' >> beam.Map(print)\n",
        "    average | 'Print average' >> beam.Map(print)"
      ],
      "metadata": {
        "id": "cybPvm63D4Vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8b5d6f-8a3e-4b33-8573-e700077b9211"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Apache-beam dökümantasyonunda bulunan örnekte ise  farklı set'leri içeren PCollectionlarda birleştirerek\n",
        "bu set'lerin kesişimini bulan bir Apache Beam işlemini gerçekleştiriyor.\n",
        "\"\"\"\n",
        "def get_common_items(sets):\n",
        "    return set.intersection(*(sets or [set()]))\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    common_items = (\n",
        "        pipeline\n",
        "        | 'Create produce' >> beam.Create([\n",
        "            {'🍓', '🥕', '🍌', '🍅', '🌶️'},\n",
        "            {'🍇', '🥕', '🥝', '🍅', '🥔'},\n",
        "            {'🍉', '🥕', '🍆', '🍅', '🍍'},\n",
        "            {'🥑', '🥕', '🌽', '🍅', '🥥'},\n",
        "        ])\n",
        "        | 'Get common items' >> beam.CombineGlobally(get_common_items)\n",
        "        | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0Ykw_7zCSuM",
        "outputId": "4ee79617-0559-49a0-be1b-02f141ff8995"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'🍅', '🥕'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Bu kod, beam.CombineGlobally() işlemi içinde bir işlev kullanarak farklı set'leri birleştirerek\n",
        "bu set'lerin kesişimini bulan bir Apache Beam işlemini gerçekleştiriyor.\n",
        "Ancak bu sefer, belirli öğeleri kesişimden çıkararak istisnaları işliyor.\n",
        "\"\"\"\n",
        "with beam.Pipeline() as pipeline:\n",
        "    common_items_with_exceptions = (\n",
        "        pipeline\n",
        "        | 'Create produce' >> beam.Create([\n",
        "            {'🍓', '🥕', '🍌', '🍅', '🌶️'},\n",
        "            {'🍇', '🥕', '🥝', '🍅', '🥔'},\n",
        "            {'🍉', '🥕', '🍆', '🍅', '🍍'},\n",
        "            {'🥑', '🥕', '🌽', '🍅', '🥥'},\n",
        "        ])\n",
        "        | 'Get common items with exceptions' >> beam.CombineGlobally(\n",
        "            lambda sets, exclude: \\\n",
        "                set.intersection(*(sets or [set()])) - exclude,\n",
        "            exclude={'🥕'})\n",
        "        | beam.Map(print)\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaAQvbqVDZaT",
        "outputId": "a2f1fad7-282d-42b6-b68f-404adcca7293"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'🍅'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CombinePerKey\n",
        "\n",
        "CombinePerKey, Apache Beam içinde her bir anahtara sahip öğeleri birleştirmek ve bu birleştirme işlemi sonucunda bir PCollection oluşturmak için kullanılan bir dönüşüm işlemidir. Bu işlem, belirli bir anahtara sahip öğeleri gruplayarak birleştirir ve sonuç olarak her bir anahtar için bir çıktı üretir.\n",
        "\n",
        "CombinePerKey işlemi, GroupByKey işlemine benzer. Ancak, GroupByKey işlemi her bir anahtar için bir grup oluştururken, CombinePerKey işlemi bu grupları birleştirerek sonuçları üretir. Bu işlem sayesinde her anahtar için bir grup oluşturmak yerine, her anahtar için bir sonuç üretilir."
      ],
      "metadata": {
        "id": "9y1ZxYBWEDf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_fn(values):\n",
        "    return sum(values)\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    orders = pipeline | 'Create orders' >> beam.Create([\n",
        "        ('apple', 3),\n",
        "        ('banana', 2),\n",
        "        ('apple', 5),\n",
        "        ('banana', 1),\n",
        "        ('orange', 4),\n",
        "    ])\n",
        "\n",
        "    combined_orders = orders | 'Combine orders' >> beam.CombinePerKey(combine_fn)\n",
        "\n",
        "    combined_orders | beam.Map(print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N7SGS6sENQF",
        "outputId": "308b26ae-a7f3-4c78-ebc9-80ead985dcea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('apple', 8)\n",
            "('banana', 3)\n",
            "('orange', 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count.Globally()\n",
        "\n",
        "Count.Globally() Apache Beam'de kullanılan bir işlevdir ve bir PCollection içindeki öğelerin toplam sayısını hesaplamak için kullanılır. Bu işlev, tüm veri kümesinin genel sayısını döndürür."
      ],
      "metadata": {
        "id": "SFBKrKtaKmrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    numbers = pipeline | 'Create numbers' >> beam.Create([1, 2, 3, 4, 5])\n",
        "\n",
        "    total_count = numbers | 'Calculate total count' >> beam.combiners.Count.Globally()\n",
        "\n",
        "    total_count | 'Print total count' >> beam.Map(print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVv4RXdKKrQ4",
        "outputId": "1b753761-6922-4e14-ee07-6408e4ef1fee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" apache beam dökümantasyonu içinde yer alan örnekte Count.PerKey() kullanımı Key değerleri ile birlikte Pcollection içinde kaç adet olduğunu döndürür.\"\"\"\n",
        "with beam.Pipeline() as pipeline:\n",
        "    total_elements_per_keys = (\n",
        "        pipeline\n",
        "        | 'Create plants' >> beam.Create([\n",
        "            ('spring', '🍓'),\n",
        "            ('spring', '🥕'),\n",
        "            ('summer', '🥕'),\n",
        "            ('fall', '🥕'),\n",
        "            ('spring', '🍆'),\n",
        "            ('winter', '🍆'),\n",
        "            ('spring', '🍅'),\n",
        "            ('summer', '🍅'),\n",
        "            ('fall', '🍅'),\n",
        "            ('summer', '🌽'),\n",
        "        ])\n",
        "        | 'Count elements per key' >> beam.combiners.Count.PerKey()\n",
        "        | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY-CFSllKuS0",
        "outputId": "ad867a0d-e964-4904-983c-6dfbddd53876"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('spring', 4)\n",
            "('summer', 3)\n",
            "('fall', 2)\n",
            "('winter', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Yine aynı şekilde yer alan diğer bir örnekte Pcollection içide yer alan her bir elementten kaç adet olduğunu döndüren bir PerElement() kullanım örneği\n",
        "\"\"\"\n",
        "with beam.Pipeline() as pipeline:\n",
        "    total_unique_elements = (\n",
        "        pipeline\n",
        "        | 'Create produce' >> beam.Create(\n",
        "            ['🍓', '🥕', '🥕', '🥕', '🍆', '🍆', '🍅', '🍅', '🍅', '🌽'])\n",
        "        | 'Count unique elements' >> beam.combiners.Count.PerElement()\n",
        "        | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOEigMi4LPIU",
        "outputId": "c6dddf99-db87-4021-b3fb-87d169a00a0d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('🍓', 1)\n",
            "('🥕', 3)\n",
            "('🍆', 2)\n",
            "('🍅', 3)\n",
            "('🌽', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GroupBy(), GroupByKey() , GroupIntoBatches()\n",
        "# GroupBy():\n",
        "GroupBy işlemi, belirli bir özelliğe göre verileri gruplamak ve bu grupları işlemek için kullanılır. Örneğin, belirli bir anahtar sütunu kullanarak verileri gruplandırmak ve bu gruplarda istatistiksel hesaplamalar yapmak gibi durumlar için kullanılabilir.\n",
        "\n",
        "# GroupByKey():\n",
        "GroupByKey işlemi, anahtar-değer çiftleri içeren verileri, anahtarlara göre gruplandırmak için kullanılır. Bu operasyon, Apache Beam'in anahtar-tabanlı işlem modeline uygun olarak tasarlanmıştır. Bu sayede aynı anahtara sahip veriler bir araya getirilir ve daha sonra bu anahtarın değeri üzerinde işlem yapılabilir.\n",
        "\n",
        "# GroupIntoBatches():\n",
        "GroupIntoBatches işlemi, belirli bir boyutta veri grupları (batch'ler) oluşturmak için kullanılır. Bu işlem, büyük veri kümelerini daha küçük gruplara bölmek ve bu gruplar üzerinde işlem yapmak için kullanılabilir. Batch işleme senaryolarında kullanışlıdır."
      ],
      "metadata": {
        "id": "Or2-4y2iIUVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Veri akışı oluşturalım\n",
        "veri = [\n",
        "    ('anahtar1', 10),\n",
        "    ('anahtar2', 20),\n",
        "    ('anahtar1', 30),\n",
        "    ('anahtar2', 25),\n",
        "    ('anahtar3', 15)\n",
        "]\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    veri_akisi = pipeline | beam.Create(veri)\n",
        "\n",
        "    # GroupByKey ile anahtara göre gruplandırma yapalım\n",
        "    gruplar = veri_akisi | beam.GroupByKey()\n",
        "\n",
        "    # Grupları yazdıralım\n",
        "    gruplar | beam.Map(print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCotrsIBITUe",
        "outputId": "0a7b6514-588d-48b3-c4c3-19bd76906f85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('anahtar1', [10, 30])\n",
            "('anahtar2', [20, 25])\n",
            "('anahtar3', [15])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "# Veri akışı oluşturalım\n",
        "veri = [\n",
        "    ('anahtar1', 10),\n",
        "    ('anahtar2', 20),\n",
        "    ('anahtar1', 30),\n",
        "    ('anahtar2', 25),\n",
        "    ('anahtar3', 15)\n",
        "]\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    veri_akisi = pipeline | beam.Create(veri)\n",
        "\n",
        "    # GroupByKey ile anahtara göre gruplandıralım\n",
        "    gruplar = veri_akisi | beam.GroupByKey()\n",
        "\n",
        "    # Her grup için toplamı hesaplayan bir ParDo işlevi\n",
        "    def hesapla_toplam(element):\n",
        "        anahtar, degerler = element\n",
        "        toplam = sum(degerler)\n",
        "        return [(anahtar, toplam)]\n",
        "\n",
        "    # Grupları toplamı hesaplayarak işle\n",
        "    toplamlar = gruplar | beam.ParDo(hesapla_toplam)\n",
        "\n",
        "    # Toplam sonuçları yazdıralım\n",
        "    toplamlar | beam.Map(print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbRCjtXvPiKE",
        "outputId": "61b0b4f2-63b7-4586-e08c-2c68778d3c62"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('anahtar1', 40)\n",
            "('anahtar2', 45)\n",
            "('anahtar3', 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Veriyi anahtar-değer çiftlerine dönüştürelim\n",
        "veri = [1,1,1,2,2,2,2,2,5,4,6,4,7,89,78]\n",
        "veri_ciftleri = [(i, i) for i in veri]\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    veri_akisi = pipeline | beam.Create(veri_ciftleri)\n",
        "\n",
        "    # Veriyi belirli boyuttaki batch'lere bölelim\n",
        "    batchler = veri_akisi | beam.GroupIntoBatches(3) #1 keyine karşılık gelen 3 adet value var , 2 keyine karşılık gelen 5 adet value değeri var fakat 3 erli gruplandığı için başka bir batche geçerek gruplamaya devam ediyor.\n",
        "\n",
        "    # Batch'leri yazdıralım\n",
        "    batchler | beam.Map(print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_H_4U48Tpih",
        "outputId": "b2993dd7-de33-4df1-c7dd-ec5413b88bda"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, [1, 1, 1])\n",
            "(2, [2, 2, 2])\n",
            "(2, [2, 2])\n",
            "(5, [5])\n",
            "(4, [4, 4])\n",
            "(6, [6])\n",
            "(7, [7])\n",
            "(89, [89])\n",
            "(78, [78])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lates\n",
        "\n",
        "Apache Beam içinde \"Latest\" işlemi, gelen verileri belirli bir anahtar ile gruplayarak, her grup için en son gelen veriyi seçmenizi sağlar. Bu işlem, her anahtarın en son durumunu veya güncel değerini bulmak için kullanışlıdır.\n",
        "\n",
        "Örnek olarak, \"Latest\" işlemi kullanarak anahtarlarla ilişkilendirilmiş en son değeri seçmek istediğinizi varsayalım. Aşağıda bu işlemi gösteren bir Apache Beam örneği bulabilirsiniz:"
      ],
      "metadata": {
        "id": "EFZs1bDcXiZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "beam.combiners.Latest.Globally() Apache Beam içinde kullanılan bir CombineGlobally işlemidir. Bu işlem, tüm gelen veriler arasında en son gelen değeri seçmenizi sağlar. Yani, tüm verileri birleştirip en son gelen veriyi seçer."
      ],
      "metadata": {
        "id": "jd3icYxZbLlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def to_unix_time(time_str, format='%Y-%m-%d %H:%M:%S'):\n",
        "    return time.mktime(time.strptime(time_str, format))\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    latest_element = (\n",
        "        pipeline\n",
        "        | 'Create crops' >> beam.Create([\n",
        "            {\n",
        "                'item': '🥬', 'harvest': '2020-02-24 00:00:00'\n",
        "            },\n",
        "            {\n",
        "                'item': '🍓', 'harvest': '2020-06-16 00:00:00'\n",
        "            },\n",
        "            {\n",
        "                'item': '🥕', 'harvest': '2020-07-17 00:00:00'\n",
        "            },\n",
        "            {\n",
        "                'item': '🍆', 'harvest': '2020-10-26 00:00:00'\n",
        "            },\n",
        "            {\n",
        "                'item': '🍅', 'harvest': '2020-10-01 00:00:00'\n",
        "            },\n",
        "        ])\n",
        "        | 'With timestamps' >> beam.Map(\n",
        "            lambda crop: beam.window.TimestampedValue(\n",
        "                crop['item'], to_unix_time(crop['harvest']))) #to_unix_time(crop['harvest'])) ifadesi, bir crop verisini alır ve crop verisindeki item değerini, to_unix_time(crop['harvest']) zaman damgası ile işaretler.\n",
        "        | 'Get latest element' >> beam.combiners.Latest.Globally()\n",
        "        | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJhzEamBZOzW",
        "outputId": "2594d099-2ff3-413e-bd44-caf75c66b04f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🍆\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "beam.combiners.Latest.PerKey() Apache Beam içinde kullanılan bir CombinePerKey işlemidir. Bu işlem, verileri belirli bir anahtar ile gruplayarak her anahtar grubunda en son gelen değeri seçmenizi sağlar.\n",
        "\n",
        "Özellikle zaman serisi verilerini işlerken veya güncel durumları takip ederken kullanışlıdır. Her anahtar grubundaki en son veriyi seçerek grupları güncel bir şekilde yönetebilirsiniz."
      ],
      "metadata": {
        "id": "TyUlNzCabEBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "veri = [\n",
        "    ('anahtar1', 10),\n",
        "    ('anahtar2', 20),\n",
        "    ('anahtar1', 30),\n",
        "    ('anahtar2', 25),\n",
        "    ('anahtar3', 15)\n",
        "]\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    veri_akisi = pipeline | beam.Create(veri)\n",
        "\n",
        "    # Veriyi anahtarlarına göre gruplandıralım ve en son veriyi seçelim\n",
        "    latest_veri = (\n",
        "        veri_akisi\n",
        "        | beam.GroupByKey()\n",
        "        | beam.Map(lambda element: (element[0], max(element[1])))\n",
        "    )\n",
        "\n",
        "    # En son verileri yazdıralım\n",
        "    latest_veri | beam.Map(print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Drrp7JvXk8X",
        "outputId": "47a0dce7-f4dc-4bdc-9a52-734dc9537a73"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('anahtar1', 30)\n",
            "('anahtar2', 25)\n",
            "('anahtar3', 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_unix_time(time_str, format='%Y-%m-%d %H:%M:%S'):\n",
        "    return time.mktime(time.strptime(time_str, format))\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    latest_elements_per_key = (\n",
        "        pipeline\n",
        "        | 'Create crops' >> beam.Create([\n",
        "            ('spring', {\n",
        "                'item': '🥕', 'harvest': '2020-06-28 00:00:00'\n",
        "            }),\n",
        "            ('spring', {\n",
        "                'item': '🍓', 'harvest': '2020-06-16 00:00:00'\n",
        "            }),\n",
        "            ('summer', {\n",
        "                'item': '🥕', 'harvest': '2020-07-17 00:00:00'\n",
        "            }),\n",
        "            ('summer', {\n",
        "                'item': '🍅', 'harvest': '2020-09-22 00:00:00'\n",
        "            }),\n",
        "            ('autumn', {\n",
        "                'item': '🍅', 'harvest': '2020-10-01 00:00:00'\n",
        "            }),\n",
        "            ('autumn', {\n",
        "                'item': '🥬', 'harvest': '2020-10-20 00:00:00'\n",
        "            }),\n",
        "            ('autumn', {\n",
        "                'item': '🍆', 'harvest': '2020-10-26 00:00:00'\n",
        "            }),\n",
        "            ('winter', {\n",
        "                'item': '🥬', 'harvest': '2020-02-24 00:00:00'\n",
        "            }),\n",
        "        ])\n",
        "        | 'With timestamps' >> beam.Map(\n",
        "            lambda pair: beam.window.TimestampedValue(\n",
        "                (pair[0], pair[1]['item']), to_unix_time(pair[1]['harvest'])))\n",
        "        | 'Get latest elements per key' >> beam.combiners.Latest.PerKey()\n",
        "        | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu_e_rtVayQv",
        "outputId": "a43e5332-05f2-4282-dc37-42d5e7e62e79"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('spring', '🥕')\n",
            "('summer', '🍅')\n",
            "('autumn', '🍆')\n",
            "('winter', '🥬')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WindowInto()\n",
        "\n",
        "beam.WindowInto işlemi, Apache Beam içinde kullanılan bir PTransform'dir ve verileri belirli bir pencereleme stratejisi ile pencerelemek için kullanılır. Pencereleme stratejileri, zaman aralıklarına veya veri miktarına dayalı olarak verileri gruplara bölmeyi sağlar. Bu sayede belirli bir zaman dilimi veya veri miktarı içinde işlemler yapabilirsiniz."
      ],
      "metadata": {
        "id": "jhAHHhwVdlEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "    produce = (pipeline\n",
        "                 | 'Garden plants' >> beam.Create([\n",
        "                    {'name': 'Strawberry', 'season': 1585699200},  # April, 2020\n",
        "                    {'name': 'Strawberry', 'season': 1588291200},  # May, 2020\n",
        "                    {'name': 'Carrot', 'season': 1590969600},  # June, 2020\n",
        "                    {'name': 'Artichoke', 'season': 1583020800},  # March, 2020\n",
        "                    {'name': 'Artichoke', 'season': 1585699200},  # April, 2020\n",
        "                    {'name': 'Tomato', 'season': 1588291200},  # May, 2020\n",
        "                    {'name': 'Potato', 'season': 1598918400},  # September, 2020\n",
        "                  ])\n",
        "                 | 'With timestamps' >> beam.Map(lambda plant: beam.window.TimestampedValue(plant['name'], plant['season']))\n",
        "                 | 'Window into fixed 2-month windows' >> beam.WindowInto(\n",
        "                              beam.window.FixedWindows(2 * 30 * 24 * 60 * 60))\n",
        "                 | 'Count per window' >> beam.combiners.Count.PerElement()\n",
        "                 | 'Print results' >> beam.Map(print)\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqAVW81wdcN3",
        "outputId": "f5e97d8c-aef6-4774-b37a-95ce82b05805"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Strawberry', 1)\n",
            "('Strawberry', 1)\n",
            "('Carrot', 1)\n",
            "('Artichoke', 2)\n",
            "('Tomato', 1)\n",
            "('Potato', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'Window into fixed 2-month windows': Bu yorum, hangi pencereleme stratejisinin kullanıldığını belirtir. Bu örnekte 2 aylık sabit pencereleme stratejisi kullanılıyor.\n",
        "\n",
        "beam.WindowInto(beam.window.FixedWindows(2 * 30 * 24 * 60 * 60)): Bu ifade, pencerelemeyi ayarlayan bölümdür.\n",
        "\n",
        "beam.window.FixedWindows(2 * 30 * 24 * 60 * 60) ifadesi, 2 ay (2 * 30 gün) boyunca sürekli olarak sabit büyüklükte (saniye cinsinden) pencereleme yapılacağını belirtir.\n",
        "\n",
        "beam.WindowInto(...) işlemi, verileri belirli pencerelere bölen bir işlemi temsil eder. İşte bu pencereleme stratejisi ile belirli bir zaman aralığı boyunca gelen verileri gruplayabilirsiniz.\n",
        "\n",
        "Bu tür pencerelemeler, özellikle zaman serisi verileri işlerken veya belirli zaman dilimlerine göre analiz yaparken kullanışlıdır. Pencereleme stratejileri, veri analizini belirli zaman dilimlerine uygun bir şekilde sınırlamak veya daha iyi paralel işlem yapmak için kullanılır."
      ],
      "metadata": {
        "id": "9KqU3wM1dsEs"
      }
    }
  ]
}